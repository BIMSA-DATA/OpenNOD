{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3D3XoBbdt40O"
      },
      "source": [
        "This is a companion notebook for the book [Deep Learning with Python, Third Edition](https://www.manning.com/books/deep-learning-with-python-third-edition). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
        "\n",
        "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
        "\n",
        "The book's contents are available online at [deeplearningwithpython.io](https://deeplearningwithpython.io)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5ca6nvtt40O",
        "outputId": "c41307e5-58e6-44d5-851b-70cd97bee413"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/1.5 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "keras-nlp 0.21.1 requires keras-hub==0.21.1, but you have keras-hub 0.25.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install keras keras-hub --upgrade -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rRr7HAYzt40P"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"jax\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "GTZAUyqFt40P"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "import os\n",
        "from IPython.core.magic import register_cell_magic\n",
        "\n",
        "@register_cell_magic\n",
        "def backend(line, cell):\n",
        "    current, required = os.environ.get(\"KERAS_BACKEND\", \"\"), line.split()[-1]\n",
        "    if current == required:\n",
        "        get_ipython().run_cell(cell)\n",
        "    else:\n",
        "        print(\n",
        "            f\"This cell requires the {required} backend. To run it, change KERAS_BACKEND to \"\n",
        "            f\"\\\"{required}\\\" at the top of the notebook, restart the runtime, and rerun the notebook.\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjBzgMh8t40P"
      },
      "source": [
        "## Best practices for the real world"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l03sJnICt40Q"
      },
      "source": [
        "### Getting the most out of your models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwF4iMB7t40Q"
      },
      "source": [
        "#### Hyperparameter optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x33dRTQat40Q"
      },
      "source": [
        "##### Using KerasTuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1zc8kHjt40Q",
        "outputId": "48a69f7f-f59c-4f71-c582-9a7bcc3a6af6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install keras-tuner -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_ADxkinRt40Q"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "def build_model(hp):\n",
        "    units = hp.Int(name=\"units\", min_value=16, max_value=64, step=16)\n",
        "    model = keras.Sequential(\n",
        "        [\n",
        "            layers.Dense(units, activation=\"relu\"),\n",
        "            layers.Dense(10, activation=\"softmax\"),\n",
        "        ]\n",
        "    )\n",
        "    optimizer = hp.Choice(name=\"optimizer\", values=[\"rmsprop\", \"adam\"])\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "o1vjYrUPt40R"
      },
      "outputs": [],
      "source": [
        "import keras_tuner as kt\n",
        "\n",
        "class SimpleMLP(kt.HyperModel):\n",
        "    def __init__(self, num_classes):\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def build(self, hp):\n",
        "        units = hp.Int(name=\"units\", min_value=16, max_value=64, step=16)\n",
        "        model = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(units, activation=\"relu\"),\n",
        "                layers.Dense(self.num_classes, activation=\"softmax\"),\n",
        "            ]\n",
        "        )\n",
        "        optimizer = hp.Choice(name=\"optimizer\", values=[\"rmsprop\", \"adam\"])\n",
        "        model.compile(\n",
        "            optimizer=optimizer,\n",
        "            loss=\"sparse_categorical_crossentropy\",\n",
        "            metrics=[\"accuracy\"],\n",
        "        )\n",
        "        return model\n",
        "\n",
        "hypermodel = SimpleMLP(num_classes=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FLyMlZQ3t40R"
      },
      "outputs": [],
      "source": [
        "tuner = kt.BayesianOptimization(\n",
        "    build_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=20,\n",
        "    executions_per_trial=2,\n",
        "    directory=\"mnist_kt_test\",\n",
        "    overwrite=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0AcsslIt40R",
        "outputId": "08d0a72e-9edd-4580-9b72-ae0144a096b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 2\n",
            "units (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 64, 'step': 16, 'sampling': 'linear'}\n",
            "optimizer (Choice)\n",
            "{'default': 'rmsprop', 'conditions': [], 'values': ['rmsprop', 'adam'], 'ordered': False}\n"
          ]
        }
      ],
      "source": [
        "tuner.search_space_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aN42NHYyt40R",
        "outputId": "f41de7c9-c229-40cc-dbc9-9636e9659086"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 20 Complete [00h 00m 34s]\n",
            "val_accuracy: 0.9746000468730927\n",
            "\n",
            "Best val_accuracy So Far: 0.9762000739574432\n",
            "Total elapsed time: 00h 12m 14s\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape((-1, 28 * 28)).astype(\"float32\") / 255\n",
        "x_test = x_test.reshape((-1, 28 * 28)).astype(\"float32\") / 255\n",
        "x_train_full = x_train[:]\n",
        "y_train_full = y_train[:]\n",
        "num_val_samples = 10000\n",
        "x_train, x_val = x_train[:-num_val_samples], x_train[-num_val_samples:]\n",
        "y_train, y_val = y_train[:-num_val_samples], y_train[-num_val_samples:]\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5),\n",
        "]\n",
        "tuner.search(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=128,\n",
        "    epochs=100,\n",
        "    validation_data=(x_val, y_val),\n",
        "    callbacks=callbacks,\n",
        "    verbose=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rFAxVrOMt40R"
      },
      "outputs": [],
      "source": [
        "top_n = 4\n",
        "best_hps = tuner.get_best_hyperparameters(top_n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5GRHYOJNt40R"
      },
      "outputs": [],
      "source": [
        "def get_best_epoch(hp):\n",
        "    model = build_model(hp)\n",
        "    callbacks = [\n",
        "        keras.callbacks.EarlyStopping(\n",
        "            monitor=\"val_loss\", mode=\"min\", patience=10\n",
        "        )\n",
        "    ]\n",
        "    history = model.fit(\n",
        "        x_train,\n",
        "        y_train,\n",
        "        validation_data=(x_val, y_val),\n",
        "        epochs=100,\n",
        "        batch_size=128,\n",
        "        callbacks=callbacks,\n",
        "    )\n",
        "    val_loss_per_epoch = history.history[\"val_loss\"]\n",
        "    best_epoch = val_loss_per_epoch.index(min(val_loss_per_epoch)) + 1\n",
        "    print(f\"Best epoch: {best_epoch}\")\n",
        "    return best_epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpdSBzHEt40R",
        "outputId": "fbe8ec34-e385-47f5-97f9-2a93ca6bed9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8750 - loss: 0.4565 - val_accuracy: 0.9346 - val_loss: 0.2341\n",
            "Epoch 2/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9371 - loss: 0.2231 - val_accuracy: 0.9509 - val_loss: 0.1788\n",
            "Epoch 3/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9505 - loss: 0.1735 - val_accuracy: 0.9552 - val_loss: 0.1609\n",
            "Epoch 4/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9590 - loss: 0.1421 - val_accuracy: 0.9600 - val_loss: 0.1379\n",
            "Epoch 5/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9659 - loss: 0.1213 - val_accuracy: 0.9642 - val_loss: 0.1229\n",
            "Epoch 6/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9700 - loss: 0.1057 - val_accuracy: 0.9667 - val_loss: 0.1135\n",
            "Epoch 7/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9735 - loss: 0.0938 - val_accuracy: 0.9683 - val_loss: 0.1104\n",
            "Epoch 8/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9769 - loss: 0.0826 - val_accuracy: 0.9700 - val_loss: 0.1056\n",
            "Epoch 9/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9785 - loss: 0.0750 - val_accuracy: 0.9684 - val_loss: 0.1087\n",
            "Epoch 10/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9806 - loss: 0.0671 - val_accuracy: 0.9720 - val_loss: 0.0979\n",
            "Epoch 11/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9827 - loss: 0.0603 - val_accuracy: 0.9720 - val_loss: 0.0956\n",
            "Epoch 12/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9847 - loss: 0.0546 - val_accuracy: 0.9720 - val_loss: 0.1001\n",
            "Epoch 13/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9858 - loss: 0.0494 - val_accuracy: 0.9720 - val_loss: 0.0968\n",
            "Epoch 14/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9867 - loss: 0.0460 - val_accuracy: 0.9730 - val_loss: 0.0945\n",
            "Epoch 15/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9889 - loss: 0.0399 - val_accuracy: 0.9741 - val_loss: 0.0948\n",
            "Epoch 16/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9897 - loss: 0.0372 - val_accuracy: 0.9716 - val_loss: 0.1029\n",
            "Epoch 17/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9909 - loss: 0.0341 - val_accuracy: 0.9737 - val_loss: 0.0946\n",
            "Epoch 18/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9922 - loss: 0.0299 - val_accuracy: 0.9748 - val_loss: 0.0932\n",
            "Epoch 19/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9928 - loss: 0.0284 - val_accuracy: 0.9755 - val_loss: 0.0932\n",
            "Epoch 20/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9938 - loss: 0.0249 - val_accuracy: 0.9735 - val_loss: 0.0996\n",
            "Epoch 21/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9948 - loss: 0.0232 - val_accuracy: 0.9743 - val_loss: 0.0959\n",
            "Epoch 22/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9956 - loss: 0.0205 - val_accuracy: 0.9734 - val_loss: 0.1027\n",
            "Epoch 23/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9961 - loss: 0.0187 - val_accuracy: 0.9741 - val_loss: 0.1009\n",
            "Epoch 24/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9961 - loss: 0.0177 - val_accuracy: 0.9736 - val_loss: 0.1017\n",
            "Epoch 25/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9971 - loss: 0.0157 - val_accuracy: 0.9746 - val_loss: 0.1032\n",
            "Epoch 26/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9973 - loss: 0.0145 - val_accuracy: 0.9739 - val_loss: 0.1092\n",
            "Epoch 27/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9978 - loss: 0.0126 - val_accuracy: 0.9748 - val_loss: 0.1061\n",
            "Epoch 28/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9982 - loss: 0.0117 - val_accuracy: 0.9756 - val_loss: 0.1041\n",
            "Best epoch: 18\n",
            "Epoch 1/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.8833 - loss: 0.4311\n",
            "Epoch 2/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9452 - loss: 0.1977\n",
            "Epoch 3/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9571 - loss: 0.1505\n",
            "Epoch 4/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9650 - loss: 0.1220\n",
            "Epoch 5/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9702 - loss: 0.1030\n",
            "Epoch 6/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9743 - loss: 0.0887\n",
            "Epoch 7/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9771 - loss: 0.0785\n",
            "Epoch 8/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9805 - loss: 0.0689\n",
            "Epoch 9/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9819 - loss: 0.0624\n",
            "Epoch 10/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9837 - loss: 0.0561\n",
            "Epoch 11/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9855 - loss: 0.0506\n",
            "Epoch 12/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9869 - loss: 0.0455\n",
            "Epoch 13/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9884 - loss: 0.0409\n",
            "Epoch 14/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9894 - loss: 0.0375\n",
            "Epoch 15/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9903 - loss: 0.0335\n",
            "Epoch 16/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9914 - loss: 0.0312\n",
            "Epoch 17/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9924 - loss: 0.0276\n",
            "Epoch 18/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9934 - loss: 0.0253\n",
            "Epoch 19/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9941 - loss: 0.0230\n",
            "Epoch 20/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9948 - loss: 0.0211\n",
            "Epoch 21/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9950 - loss: 0.0195\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9749 - loss: 0.0874\n",
            "Epoch 1/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8698 - loss: 0.4719 - val_accuracy: 0.9391 - val_loss: 0.2256\n",
            "Epoch 2/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9408 - loss: 0.2085 - val_accuracy: 0.9538 - val_loss: 0.1669\n",
            "Epoch 3/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9556 - loss: 0.1552 - val_accuracy: 0.9609 - val_loss: 0.1361\n",
            "Epoch 4/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9643 - loss: 0.1262 - val_accuracy: 0.9647 - val_loss: 0.1228\n",
            "Epoch 5/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9691 - loss: 0.1067 - val_accuracy: 0.9679 - val_loss: 0.1133\n",
            "Epoch 6/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9733 - loss: 0.0927 - val_accuracy: 0.9692 - val_loss: 0.1048\n",
            "Epoch 7/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9763 - loss: 0.0815 - val_accuracy: 0.9687 - val_loss: 0.1045\n",
            "Epoch 8/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9796 - loss: 0.0719 - val_accuracy: 0.9706 - val_loss: 0.0977\n",
            "Epoch 9/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9816 - loss: 0.0644 - val_accuracy: 0.9693 - val_loss: 0.1000\n",
            "Epoch 10/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9841 - loss: 0.0578 - val_accuracy: 0.9740 - val_loss: 0.0898\n",
            "Epoch 11/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9859 - loss: 0.0518 - val_accuracy: 0.9727 - val_loss: 0.0897\n",
            "Epoch 12/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9868 - loss: 0.0472 - val_accuracy: 0.9700 - val_loss: 0.0936\n",
            "Epoch 13/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9880 - loss: 0.0434 - val_accuracy: 0.9733 - val_loss: 0.0871\n",
            "Epoch 14/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9897 - loss: 0.0388 - val_accuracy: 0.9739 - val_loss: 0.0853\n",
            "Epoch 15/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9907 - loss: 0.0351 - val_accuracy: 0.9737 - val_loss: 0.0854\n",
            "Epoch 16/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9911 - loss: 0.0320 - val_accuracy: 0.9728 - val_loss: 0.0903\n",
            "Epoch 17/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9928 - loss: 0.0288 - val_accuracy: 0.9746 - val_loss: 0.0882\n",
            "Epoch 18/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9935 - loss: 0.0267 - val_accuracy: 0.9745 - val_loss: 0.0905\n",
            "Epoch 19/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9942 - loss: 0.0235 - val_accuracy: 0.9744 - val_loss: 0.0885\n",
            "Epoch 20/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9945 - loss: 0.0219 - val_accuracy: 0.9745 - val_loss: 0.0881\n",
            "Epoch 21/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9954 - loss: 0.0198 - val_accuracy: 0.9722 - val_loss: 0.0954\n",
            "Epoch 22/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9961 - loss: 0.0177 - val_accuracy: 0.9726 - val_loss: 0.0903\n",
            "Epoch 23/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9962 - loss: 0.0167 - val_accuracy: 0.9725 - val_loss: 0.0934\n",
            "Epoch 24/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9972 - loss: 0.0144 - val_accuracy: 0.9744 - val_loss: 0.0933\n",
            "Best epoch: 14\n",
            "Epoch 1/16\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8817 - loss: 0.4306\n",
            "Epoch 2/16\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9409 - loss: 0.2060\n",
            "Epoch 3/16\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9540 - loss: 0.1596\n",
            "Epoch 4/16\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9635 - loss: 0.1290\n",
            "Epoch 5/16\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9690 - loss: 0.1077\n",
            "Epoch 6/16\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9733 - loss: 0.0927\n",
            "Epoch 7/16\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9763 - loss: 0.0812\n",
            "Epoch 8/16\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9797 - loss: 0.0713\n",
            "Epoch 9/16\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9815 - loss: 0.0634\n",
            "Epoch 10/16\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9829 - loss: 0.0578\n",
            "Epoch 11/16\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9852 - loss: 0.0512\n",
            "Epoch 12/16\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9869 - loss: 0.0463\n",
            "Epoch 13/16\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9879 - loss: 0.0423\n",
            "Epoch 14/16\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9891 - loss: 0.0375\n",
            "Epoch 15/16\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9908 - loss: 0.0339\n",
            "Epoch 16/16\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9916 - loss: 0.0308\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9746 - loss: 0.0841\n",
            "Epoch 1/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8759 - loss: 0.4587 - val_accuracy: 0.9318 - val_loss: 0.2452\n",
            "Epoch 2/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9375 - loss: 0.2245 - val_accuracy: 0.9496 - val_loss: 0.1844\n",
            "Epoch 3/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9485 - loss: 0.1769 - val_accuracy: 0.9573 - val_loss: 0.1544\n",
            "Epoch 4/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9583 - loss: 0.1460 - val_accuracy: 0.9610 - val_loss: 0.1426\n",
            "Epoch 5/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9641 - loss: 0.1252 - val_accuracy: 0.9627 - val_loss: 0.1331\n",
            "Epoch 6/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9690 - loss: 0.1087 - val_accuracy: 0.9654 - val_loss: 0.1198\n",
            "Epoch 7/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9732 - loss: 0.0952 - val_accuracy: 0.9670 - val_loss: 0.1147\n",
            "Epoch 8/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9763 - loss: 0.0846 - val_accuracy: 0.9694 - val_loss: 0.1059\n",
            "Epoch 9/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9793 - loss: 0.0749 - val_accuracy: 0.9673 - val_loss: 0.1094\n",
            "Epoch 10/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9814 - loss: 0.0677 - val_accuracy: 0.9689 - val_loss: 0.1029\n",
            "Epoch 11/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9834 - loss: 0.0599 - val_accuracy: 0.9694 - val_loss: 0.1039\n",
            "Epoch 12/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9844 - loss: 0.0552 - val_accuracy: 0.9705 - val_loss: 0.0999\n",
            "Epoch 13/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9864 - loss: 0.0492 - val_accuracy: 0.9713 - val_loss: 0.0985\n",
            "Epoch 14/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9883 - loss: 0.0443 - val_accuracy: 0.9702 - val_loss: 0.1009\n",
            "Epoch 15/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9891 - loss: 0.0400 - val_accuracy: 0.9710 - val_loss: 0.0974\n",
            "Epoch 16/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9905 - loss: 0.0360 - val_accuracy: 0.9685 - val_loss: 0.1041\n",
            "Epoch 17/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9914 - loss: 0.0329 - val_accuracy: 0.9705 - val_loss: 0.1000\n",
            "Epoch 18/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9926 - loss: 0.0294 - val_accuracy: 0.9708 - val_loss: 0.1030\n",
            "Epoch 19/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9934 - loss: 0.0275 - val_accuracy: 0.9727 - val_loss: 0.1007\n",
            "Epoch 20/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9940 - loss: 0.0244 - val_accuracy: 0.9699 - val_loss: 0.1090\n",
            "Epoch 21/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9951 - loss: 0.0220 - val_accuracy: 0.9718 - val_loss: 0.1037\n",
            "Epoch 22/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9955 - loss: 0.0198 - val_accuracy: 0.9718 - val_loss: 0.1038\n",
            "Epoch 23/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9962 - loss: 0.0178 - val_accuracy: 0.9713 - val_loss: 0.1100\n",
            "Epoch 24/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9968 - loss: 0.0158 - val_accuracy: 0.9697 - val_loss: 0.1086\n",
            "Epoch 25/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9971 - loss: 0.0143 - val_accuracy: 0.9724 - val_loss: 0.1081\n",
            "Best epoch: 15\n",
            "Epoch 1/18\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8857 - loss: 0.4196\n",
            "Epoch 2/18\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9421 - loss: 0.2050\n",
            "Epoch 3/18\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9555 - loss: 0.1590\n",
            "Epoch 4/18\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9624 - loss: 0.1307\n",
            "Epoch 5/18\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9672 - loss: 0.1109\n",
            "Epoch 6/18\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9724 - loss: 0.0954\n",
            "Epoch 7/18\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9759 - loss: 0.0830\n",
            "Epoch 8/18\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9785 - loss: 0.0737\n",
            "Epoch 9/18\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9812 - loss: 0.0661\n",
            "Epoch 10/18\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9830 - loss: 0.0595\n",
            "Epoch 11/18\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9847 - loss: 0.0527\n",
            "Epoch 12/18\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9864 - loss: 0.0477\n",
            "Epoch 13/18\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9880 - loss: 0.0429\n",
            "Epoch 14/18\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9889 - loss: 0.0392\n",
            "Epoch 15/18\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9901 - loss: 0.0360\n",
            "Epoch 16/18\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9913 - loss: 0.0322\n",
            "Epoch 17/18\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9918 - loss: 0.0297\n",
            "Epoch 18/18\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9929 - loss: 0.0268\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9753 - loss: 0.0891\n",
            "Epoch 1/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8768 - loss: 0.4562 - val_accuracy: 0.9376 - val_loss: 0.2358\n",
            "Epoch 2/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9383 - loss: 0.2196 - val_accuracy: 0.9533 - val_loss: 0.1781\n",
            "Epoch 3/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9521 - loss: 0.1700 - val_accuracy: 0.9585 - val_loss: 0.1503\n",
            "Epoch 4/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9609 - loss: 0.1378 - val_accuracy: 0.9638 - val_loss: 0.1305\n",
            "Epoch 5/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9667 - loss: 0.1164 - val_accuracy: 0.9651 - val_loss: 0.1181\n",
            "Epoch 6/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9717 - loss: 0.1006 - val_accuracy: 0.9664 - val_loss: 0.1123\n",
            "Epoch 7/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9749 - loss: 0.0880 - val_accuracy: 0.9680 - val_loss: 0.1086\n",
            "Epoch 8/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9780 - loss: 0.0780 - val_accuracy: 0.9690 - val_loss: 0.1058\n",
            "Epoch 9/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9805 - loss: 0.0696 - val_accuracy: 0.9684 - val_loss: 0.1043\n",
            "Epoch 10/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9819 - loss: 0.0626 - val_accuracy: 0.9700 - val_loss: 0.1001\n",
            "Epoch 11/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9844 - loss: 0.0552 - val_accuracy: 0.9719 - val_loss: 0.0948\n",
            "Epoch 12/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9856 - loss: 0.0500 - val_accuracy: 0.9730 - val_loss: 0.0922\n",
            "Epoch 13/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9877 - loss: 0.0448 - val_accuracy: 0.9737 - val_loss: 0.0911\n",
            "Epoch 14/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9881 - loss: 0.0410 - val_accuracy: 0.9742 - val_loss: 0.0910\n",
            "Epoch 15/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9901 - loss: 0.0370 - val_accuracy: 0.9722 - val_loss: 0.0939\n",
            "Epoch 16/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9911 - loss: 0.0332 - val_accuracy: 0.9722 - val_loss: 0.0908\n",
            "Epoch 17/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9925 - loss: 0.0292 - val_accuracy: 0.9740 - val_loss: 0.0874\n",
            "Epoch 18/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9927 - loss: 0.0273 - val_accuracy: 0.9740 - val_loss: 0.0869\n",
            "Epoch 19/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9938 - loss: 0.0245 - val_accuracy: 0.9740 - val_loss: 0.0912\n",
            "Epoch 20/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9942 - loss: 0.0222 - val_accuracy: 0.9738 - val_loss: 0.0892\n",
            "Epoch 21/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9953 - loss: 0.0198 - val_accuracy: 0.9747 - val_loss: 0.0888\n",
            "Epoch 22/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9962 - loss: 0.0175 - val_accuracy: 0.9746 - val_loss: 0.0907\n",
            "Epoch 23/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9963 - loss: 0.0165 - val_accuracy: 0.9746 - val_loss: 0.0946\n",
            "Epoch 24/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9970 - loss: 0.0148 - val_accuracy: 0.9731 - val_loss: 0.0959\n",
            "Epoch 25/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9974 - loss: 0.0134 - val_accuracy: 0.9737 - val_loss: 0.0949\n",
            "Epoch 26/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9981 - loss: 0.0116 - val_accuracy: 0.9736 - val_loss: 0.0953\n",
            "Epoch 27/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9982 - loss: 0.0107 - val_accuracy: 0.9746 - val_loss: 0.1001\n",
            "Epoch 28/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9984 - loss: 0.0100 - val_accuracy: 0.9737 - val_loss: 0.0976\n",
            "Best epoch: 18\n",
            "Epoch 1/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8830 - loss: 0.4272\n",
            "Epoch 2/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9411 - loss: 0.2069\n",
            "Epoch 3/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9540 - loss: 0.1597\n",
            "Epoch 4/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9615 - loss: 0.1330\n",
            "Epoch 5/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9672 - loss: 0.1127\n",
            "Epoch 6/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9712 - loss: 0.0979\n",
            "Epoch 7/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9748 - loss: 0.0867\n",
            "Epoch 8/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9787 - loss: 0.0766\n",
            "Epoch 9/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9797 - loss: 0.0688\n",
            "Epoch 10/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9819 - loss: 0.0614\n",
            "Epoch 11/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9839 - loss: 0.0551\n",
            "Epoch 12/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9854 - loss: 0.0496\n",
            "Epoch 13/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9871 - loss: 0.0455\n",
            "Epoch 14/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9885 - loss: 0.0410\n",
            "Epoch 15/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9891 - loss: 0.0382\n",
            "Epoch 16/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9904 - loss: 0.0339\n",
            "Epoch 17/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9913 - loss: 0.0313\n",
            "Epoch 18/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9929 - loss: 0.0276\n",
            "Epoch 19/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9937 - loss: 0.0251\n",
            "Epoch 20/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9938 - loss: 0.0234\n",
            "Epoch 21/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9941 - loss: 0.0218\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9753 - loss: 0.0947\n"
          ]
        }
      ],
      "source": [
        "def get_best_trained_model(hp):\n",
        "    best_epoch = get_best_epoch(hp)\n",
        "    model = build_model(hp)\n",
        "    model.fit(\n",
        "        x_train_full, y_train_full, batch_size=128, epochs=int(best_epoch * 1.2)\n",
        "    )\n",
        "    return model\n",
        "\n",
        "best_models = []\n",
        "for hp in best_hps:\n",
        "    model = get_best_trained_model(hp)\n",
        "    model.evaluate(x_test, y_test)\n",
        "    best_models.append(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nf7Mga10t40R",
        "outputId": "54ce4fc2-02a3-46d4-b473-3fd2167099fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 10 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ],
      "source": [
        "best_models = tuner.get_best_models(top_n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPlNXOIKt40R"
      },
      "source": [
        "##### The art of crafting the right search space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t72plnSGt40R"
      },
      "source": [
        "##### The future of hyperparameter tuning: automated machine learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7pnV6kTt40R"
      },
      "source": [
        "#### Model ensembling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bayEVQoGt40R"
      },
      "source": [
        "### Scaling up model training with multiple devices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ie6VAfOt40R"
      },
      "source": [
        "#### Multi-GPU training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhD-JpMIt40R"
      },
      "source": [
        "##### Data parallelism: Replicating your model on each GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2nJCTlMt40R"
      },
      "source": [
        "##### Model parallelism: Splitting your model across multiple GPUs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxK1eMhtt40S"
      },
      "source": [
        "#### Distributed training in practice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlnzSjHkt40S"
      },
      "source": [
        "##### Getting your hands on two or more GPUs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4qe3kcwt40S"
      },
      "source": [
        "##### Using data parallelism with JAX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Gr0rZ1zt40S"
      },
      "source": [
        "##### Using model parallelism with JAX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45xBEkJst40S"
      },
      "source": [
        "###### The DeviceMesh API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7izUkTVt40S"
      },
      "source": [
        "###### The LayoutMap API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uT3IiZjt40S"
      },
      "source": [
        "#### TPU training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNxnVj6wt40S"
      },
      "source": [
        "##### Using step fusing to improve TPU utilization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUWuai42t40S"
      },
      "source": [
        "### Speeding up training and inference with lower-precision computation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqSZqzMMt40S"
      },
      "source": [
        "##### Understanding floating-point precision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGn0SaRIt40S"
      },
      "source": [
        "##### Float16 inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8Fc4h5Mt40S"
      },
      "source": [
        "##### Mixed-precision training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olkiR4G2t40S"
      },
      "source": [
        "##### Using loss scaling with mixed precision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OSVPahvt40S"
      },
      "source": [
        "##### Beyond mixed precision: float8 training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvea8BwJt40V"
      },
      "source": [
        "#### Faster inference with quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6acIBnyJt40V"
      },
      "outputs": [],
      "source": [
        "from keras import ops\n",
        "\n",
        "x = ops.array([[0.1, 0.9], [1.2, -0.8]])\n",
        "kernel = ops.array([[-0.1, -2.2], [1.1, 0.7]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "mmZaQ6pgt40W"
      },
      "outputs": [],
      "source": [
        "def abs_max_quantize(value):\n",
        "    abs_max = ops.max(ops.abs(value), keepdims=True)\n",
        "    scale = ops.divide(127, abs_max + 1e-7)\n",
        "    scaled_value = value * scale\n",
        "    scaled_value = ops.clip(ops.round(scaled_value), -127, 127)\n",
        "    scaled_value = ops.cast(scaled_value, dtype=\"int8\")\n",
        "    return scaled_value, scale\n",
        "\n",
        "int_x, x_scale = abs_max_quantize(x)\n",
        "int_kernel, kernel_scale = abs_max_quantize(kernel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "GHcvfvDAt40W"
      },
      "outputs": [],
      "source": [
        "int_y = ops.matmul(int_x, int_kernel)\n",
        "y = ops.cast(int_y, dtype=\"float32\") / (x_scale * kernel_scale)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5GTZlsPt40W",
        "outputId": "aa1d6d5b-aad6-4786-d17e-28fefa9bb30d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[ 1.9687474 ,  0.78664786],\n",
              "       [-2.0302913 , -6.393028  ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGJx2LI5t40W",
        "outputId": "66311f34-3140-4bf2-8934-da5855ee6aae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[ 0.98      ,  0.40999997],\n",
              "       [-1.        , -3.2       ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "ops.matmul(x, kernel)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "chapter18_best-practices-for-the-real-world",
      "provenance": [],
      "toc_visible": true,
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}