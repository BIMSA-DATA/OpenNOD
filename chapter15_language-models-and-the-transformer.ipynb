{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyV-L9YHyGfI"
      },
      "source": [
        "This is a companion notebook for the book [Deep Learning with Python, Third Edition](https://www.manning.com/books/deep-learning-with-python-third-edition). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
        "\n",
        "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
        "\n",
        "The book's contents are available online at [deeplearningwithpython.io](https://deeplearningwithpython.io)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BT9zAOupyGfJ",
        "outputId": "63b8f4ea-6503-4578-c927-db91a6ce23dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "keras-nlp 0.21.1 requires keras-hub==0.21.1, but you have keras-hub 0.25.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install keras keras-hub --upgrade -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AEW_0schyGfK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"jax\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "vOKhkKZTyGfL"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "import os\n",
        "from IPython.core.magic import register_cell_magic\n",
        "\n",
        "@register_cell_magic\n",
        "def backend(line, cell):\n",
        "    current, required = os.environ.get(\"KERAS_BACKEND\", \"\"), line.split()[-1]\n",
        "    if current == required:\n",
        "        get_ipython().run_cell(cell)\n",
        "    else:\n",
        "        print(\n",
        "            f\"This cell requires the {required} backend. To run it, change KERAS_BACKEND to \"\n",
        "            f\"\\\"{required}\\\" at the top of the notebook, restart the runtime, and rerun the notebook.\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_YIkNaiyGfM"
      },
      "source": [
        "## Language models and the Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14OJZe_0yGfN"
      },
      "source": [
        "### The language model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SCi1694yGfN"
      },
      "source": [
        "#### Training a Shakespeare language model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYUj2xPpyGfN",
        "outputId": "4bf285cf-4332-44c5-e232-fc344e4bc741"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "\u001b[1m1115394/1115394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1us/step\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "\n",
        "filename = keras.utils.get_file(\n",
        "    origin=(\n",
        "        \"https://storage.googleapis.com/download.tensorflow.org/\"\n",
        "        \"data/shakespeare.txt\"\n",
        "    ),\n",
        ")\n",
        "shakespeare = open(filename, \"r\").read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "bg6-AjbuyGfN",
        "outputId": "a795d335-fb7f-4bbc-cb8f-1309be9f2aeb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you know Caius Marcius is chief enemy to the people.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "shakespeare[:250]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rkOuv3PHyGfN"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "sequence_length = 100\n",
        "\n",
        "def split_input(input, sequence_length):\n",
        "    for i in range(0, len(input), sequence_length):\n",
        "        yield input[i : i + sequence_length]\n",
        "\n",
        "features = list(split_input(shakespeare[:-1], sequence_length))\n",
        "labels = list(split_input(shakespeare[1:], sequence_length))\n",
        "dataset = tf.data.Dataset.from_tensor_slices((features, labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5GoNhHGyGfO",
        "outputId": "0857d517-1af8-49cb-a94f-98e1fa9595d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(b'First Citizen:\\nBefore we proceed any further, hear',\n",
              " b'irst Citizen:\\nBefore we proceed any further, hear ')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "x, y = next(dataset.as_numpy_iterator())\n",
        "x[:50], y[:50]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "A_9pIeY7yGfO"
      },
      "outputs": [],
      "source": [
        "from keras import layers\n",
        "\n",
        "tokenizer = layers.TextVectorization(\n",
        "    standardize=None,\n",
        "    split=\"character\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "tokenizer.adapt(dataset.map(lambda text, labels: text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRs0gWZ4yGfO",
        "outputId": "a95db7be-97f0-4e25-a8d4-ccfdad3f6aa5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "67"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "vocabulary_size = tokenizer.vocabulary_size()\n",
        "vocabulary_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qd2dLj-ByGfO"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.map(\n",
        "    lambda features, labels: (tokenizer(features), tokenizer(labels)),\n",
        "    num_parallel_calls=8,\n",
        ")\n",
        "training_data = dataset.shuffle(10_000).batch(64).cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "MP4VsvQXyGfO"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 256\n",
        "hidden_dim = 1024\n",
        "\n",
        "inputs = layers.Input(shape=(sequence_length,), dtype=\"int\", name=\"token_ids\")\n",
        "x = layers.Embedding(vocabulary_size, embedding_dim)(inputs)\n",
        "x = layers.GRU(hidden_dim, return_sequences=True)(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "outputs = layers.Dense(vocabulary_size, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "5XQ9SACOyGfO",
        "outputId": "96300712-b6d3-4ee6-f26a-6cb762c8b605"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape            \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │        \u001b[38;5;34m17,152\u001b[0m │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)                         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1024\u001b[0m)        │     \u001b[38;5;34m3,938,304\u001b[0m │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1024\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m67\u001b[0m)          │        \u001b[38;5;34m68,675\u001b[0m │\n",
              "└───────────────────────────────────┴──────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                      </span>┃<span style=\"font-weight: bold\"> Output Shape             </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">17,152</span> │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,938,304</span> │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">67</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">68,675</span> │\n",
              "└───────────────────────────────────┴──────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,024,131\u001b[0m (15.35 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,024,131</span> (15.35 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,024,131\u001b[0m (15.35 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,024,131</span> (15.35 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary(line_length=80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiTLPFJryGfO",
        "outputId": "f8831777-215f-4fc1-f362-9fa72e94974a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 49ms/step - loss: 2.6924 - sparse_categorical_accuracy: 0.2785\n",
            "Epoch 2/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 1.9755 - sparse_categorical_accuracy: 0.4215\n",
            "Epoch 3/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 1.7115 - sparse_categorical_accuracy: 0.4918\n",
            "Epoch 4/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 1.5647 - sparse_categorical_accuracy: 0.5304\n",
            "Epoch 5/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 1.4730 - sparse_categorical_accuracy: 0.5540\n",
            "Epoch 6/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 1.4086 - sparse_categorical_accuracy: 0.5701\n",
            "Epoch 7/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 1.3575 - sparse_categorical_accuracy: 0.5833\n",
            "Epoch 8/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 1.3137 - sparse_categorical_accuracy: 0.5944\n",
            "Epoch 9/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 1.2734 - sparse_categorical_accuracy: 0.6048\n",
            "Epoch 10/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 1.2331 - sparse_categorical_accuracy: 0.6160\n",
            "Epoch 11/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 1.1929 - sparse_categorical_accuracy: 0.6272\n",
            "Epoch 12/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 1.1524 - sparse_categorical_accuracy: 0.6391\n",
            "Epoch 13/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 1.1137 - sparse_categorical_accuracy: 0.6500\n",
            "Epoch 14/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 1.0780 - sparse_categorical_accuracy: 0.6604\n",
            "Epoch 15/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 1.0486 - sparse_categorical_accuracy: 0.6692\n",
            "Epoch 16/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 1.0197 - sparse_categorical_accuracy: 0.6774\n",
            "Epoch 17/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.9893 - sparse_categorical_accuracy: 0.6864\n",
            "Epoch 18/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.9623 - sparse_categorical_accuracy: 0.6942\n",
            "Epoch 19/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.9430 - sparse_categorical_accuracy: 0.6996\n",
            "Epoch 20/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.9305 - sparse_categorical_accuracy: 0.7034\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7bf8dbe3f7a0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"sparse_categorical_accuracy\"],\n",
        ")\n",
        "model.fit(training_data, epochs=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NA-YDBeyGfO"
      },
      "source": [
        "#### Generating Shakespeare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "CV6y0eOFyGfO"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(1,), dtype=\"int\", name=\"token_ids\")\n",
        "input_state = keras.Input(shape=(hidden_dim,), name=\"state\")\n",
        "\n",
        "x = layers.Embedding(vocabulary_size, embedding_dim)(inputs)\n",
        "x, output_state = layers.GRU(hidden_dim, return_state=True)(\n",
        "    x, initial_state=input_state\n",
        ")\n",
        "outputs = layers.Dense(vocabulary_size, activation=\"softmax\")(x)\n",
        "generation_model = keras.Model(\n",
        "    inputs=(inputs, input_state),\n",
        "    outputs=(outputs, output_state),\n",
        ")\n",
        "generation_model.set_weights(model.get_weights())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "xVd9cOCAyGfO"
      },
      "outputs": [],
      "source": [
        "tokens = tokenizer.get_vocabulary()\n",
        "token_ids = range(vocabulary_size)\n",
        "char_to_id = dict(zip(tokens, token_ids))\n",
        "id_to_char = dict(zip(token_ids, tokens))\n",
        "\n",
        "prompt = \"\"\"\n",
        "KING RICHARD III:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ae9Kzj4cyGfO"
      },
      "outputs": [],
      "source": [
        "input_ids = [char_to_id[c] for c in prompt]\n",
        "state = keras.ops.zeros(shape=(1, hidden_dim))\n",
        "for token_id in input_ids:\n",
        "    inputs = keras.ops.expand_dims([token_id], axis=0)\n",
        "    predictions, state = generation_model.predict((inputs, state), verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "EhPg7dKwyGfP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "generated_ids = []\n",
        "max_length = 250\n",
        "for i in range(max_length):\n",
        "    next_char = int(np.argmax(predictions, axis=-1)[0])\n",
        "    generated_ids.append(next_char)\n",
        "    inputs = keras.ops.expand_dims([next_char], axis=0)\n",
        "    predictions, state = generation_model.predict((inputs, state), verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rIoCvlZyGfP",
        "outputId": "75d8113f-93c7-4133-d454-c8d5081dd8f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "KING RICHARD III:\n",
            "Ay, and you shall hear me.\n",
            "\n",
            "BAPTISTA:\n",
            "A mother, mother, sir.\n",
            "\n",
            "POMPEY:\n",
            "True, it is a subject done, and that will find\n",
            "That thought the lark that they are friends,'s as see and take a treachery.\n",
            "\n",
            "GLOUCESTER:\n",
            "So do I too her father. This is the father o\n"
          ]
        }
      ],
      "source": [
        "output = \"\".join([id_to_char[token_id] for token_id in generated_ids])\n",
        "print(prompt + output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7C84895yGfP"
      },
      "source": [
        "### Sequence-to-sequence learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aalLHl7yGfP"
      },
      "source": [
        "#### English-to-Spanish translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZSIziyWyGfP",
        "outputId": "1e948b73-b2c4-4bb0-b2f2-86dba70baa8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "\u001b[1m2638744/2638744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "import pathlib\n",
        "\n",
        "zip_path = keras.utils.get_file(\n",
        "    origin=(\n",
        "        \"http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\"\n",
        "    ),\n",
        "    fname=\"spa-eng\",\n",
        "    extract=True,\n",
        ")\n",
        "text_path = pathlib.Path(zip_path) / \"spa-eng\" / \"spa.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "G8Wl1VYYyGfP"
      },
      "outputs": [],
      "source": [
        "with open(text_path) as f:\n",
        "    lines = f.read().split(\"\\n\")[:-1]\n",
        "text_pairs = []\n",
        "for line in lines:\n",
        "    english, spanish = line.split(\"\\t\")\n",
        "    spanish = \"[start] \" + spanish + \" [end]\"\n",
        "    text_pairs.append((english, spanish))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTAUA0YAyGfP",
        "outputId": "1cf55892-c965-41bc-8ae9-f97204de9c56"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('I love your daughter.', '[start] Quiero a su hija. [end]')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "import random\n",
        "random.choice(text_pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "3C3g4boCyGfP"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "random.shuffle(text_pairs)\n",
        "val_samples = int(0.15 * len(text_pairs))\n",
        "train_samples = len(text_pairs) - 2 * val_samples\n",
        "train_pairs = text_pairs[:train_samples]\n",
        "val_pairs = text_pairs[train_samples : train_samples + val_samples]\n",
        "test_pairs = text_pairs[train_samples + val_samples :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "TFVtC4g_yGfP"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import re\n",
        "\n",
        "strip_chars = string.punctuation + \"¿\"\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "\n",
        "def custom_standardization(input_string):\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(\n",
        "        lowercase, f\"[{re.escape(strip_chars)}]\", \"\"\n",
        "    )\n",
        "\n",
        "vocab_size = 15000\n",
        "sequence_length = 20\n",
        "\n",
        "english_tokenizer = layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "spanish_tokenizer = layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        "    standardize=custom_standardization,\n",
        ")\n",
        "train_english_texts = [pair[0] for pair in train_pairs]\n",
        "train_spanish_texts = [pair[1] for pair in train_pairs]\n",
        "english_tokenizer.adapt(train_english_texts)\n",
        "spanish_tokenizer.adapt(train_spanish_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "3lzHP72FyGfP"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "\n",
        "def format_dataset(eng, spa):\n",
        "    eng = english_tokenizer(eng)\n",
        "    spa = spanish_tokenizer(spa)\n",
        "    features = {\"english\": eng, \"spanish\": spa[:, :-1]}\n",
        "    labels = spa[:, 1:]\n",
        "    sample_weights = labels != 0\n",
        "    return features, labels, sample_weights\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    eng_texts, spa_texts = zip(*pairs)\n",
        "    eng_texts = list(eng_texts)\n",
        "    spa_texts = list(spa_texts)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset, num_parallel_calls=4)\n",
        "    return dataset.shuffle(2048).cache()\n",
        "\n",
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xl5SG7TyGfP",
        "outputId": "abdc04bf-ea5f-4f22-bfd4-68ac083e6657"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 20)\n"
          ]
        }
      ],
      "source": [
        "inputs, targets, sample_weights = next(iter(train_ds))\n",
        "print(inputs[\"english\"].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZ8sQ43QyGfP",
        "outputId": "955548ac-0c64-4fe6-c78f-45cee755b003"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 20)\n"
          ]
        }
      ],
      "source": [
        "print(inputs[\"spanish\"].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V45zjmmKyGfP",
        "outputId": "70397751-4f14-4853-932b-9f19eac5d4d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 20)\n"
          ]
        }
      ],
      "source": [
        "print(targets.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SW2Nz2YeyGfP",
        "outputId": "17a1f1da-80ab-436c-b31f-bbf7aef3ba2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 20)\n"
          ]
        }
      ],
      "source": [
        "print(sample_weights.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENO5aObByGfP"
      },
      "source": [
        "#### Sequence-to-sequence learning with RNNs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "BDtw4FpPyGfP"
      },
      "outputs": [],
      "source": [
        "embed_dim = 256\n",
        "hidden_dim = 1024\n",
        "\n",
        "source = keras.Input(shape=(None,), dtype=\"int32\", name=\"english\")\n",
        "x = layers.Embedding(vocab_size, embed_dim, mask_zero=True)(source)\n",
        "rnn_layer = layers.GRU(hidden_dim)\n",
        "rnn_layer = layers.Bidirectional(rnn_layer, merge_mode=\"sum\")\n",
        "encoder_output = rnn_layer(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "bAfjXZMoyGfP"
      },
      "outputs": [],
      "source": [
        "target = keras.Input(shape=(None,), dtype=\"int32\", name=\"spanish\")\n",
        "x = layers.Embedding(vocab_size, embed_dim, mask_zero=True)(target)\n",
        "rnn_layer = layers.GRU(hidden_dim, return_sequences=True)\n",
        "x = rnn_layer(x, initial_state=encoder_output)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "target_predictions = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "seq2seq_rnn = keras.Model([source, target], target_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "5Is9fd39yGfP",
        "outputId": "3d462428-d00a-4fad-abf3-1d70298cefd9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m    Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to      \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ english (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │           \u001b[38;5;34m0\u001b[0m │ -                  │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ spanish (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │           \u001b[38;5;34m0\u001b[0m │ -                  │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ embedding_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │   \u001b[38;5;34m3,840,000\u001b[0m │ english[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)           │                   │             │                    │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ not_equal (\u001b[38;5;33mNotEqual\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │           \u001b[38;5;34m0\u001b[0m │ english[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ embedding_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │   \u001b[38;5;34m3,840,000\u001b[0m │ spanish[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)           │                   │             │                    │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ bidirectional         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │   \u001b[38;5;34m7,876,608\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)       │                   │             │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ gru_3 (\u001b[38;5;33mGRU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │   \u001b[38;5;34m3,938,304\u001b[0m │ embedding_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│                       │ \u001b[38;5;34m1024\u001b[0m)             │             │ bidirectional[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │           \u001b[38;5;34m0\u001b[0m │ gru_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│                       │ \u001b[38;5;34m1024\u001b[0m)             │             │                    │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │  \u001b[38;5;34m15,375,000\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│                       │ \u001b[38;5;34m15000\u001b[0m)            │             │                    │\n",
              "└───────────────────────┴───────────────────┴─────────────┴────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)          </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">     Param # </span>┃<span style=\"font-weight: bold\"> Connected to       </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ english (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                  │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ spanish (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                  │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ embedding_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │   <span style=\"color: #00af00; text-decoration-color: #00af00\">3,840,000</span> │ english[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │                   │             │                    │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ not_equal (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ english[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ embedding_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │   <span style=\"color: #00af00; text-decoration-color: #00af00\">3,840,000</span> │ spanish[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │                   │             │                    │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ bidirectional         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">7,876,608</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)       │                   │             │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ gru_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">3,938,304</span> │ embedding_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│                       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │             │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ gru_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│                       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │             │                    │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">15,375,000</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│                       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">15000</span>)            │             │                    │\n",
              "└───────────────────────┴───────────────────┴─────────────┴────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m34,869,912\u001b[0m (133.02 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,869,912</span> (133.02 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m34,869,912\u001b[0m (133.02 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,869,912</span> (133.02 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "seq2seq_rnn.summary(line_length=80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBRTAY8JyGfS",
        "outputId": "325a2770-61bb-4249-860d-e82b637d9289"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 31ms/step - accuracy: 0.3590 - loss: 3.6577 - val_accuracy: 0.4981 - val_loss: 2.4960\n",
            "Epoch 2/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 13ms/step - accuracy: 0.5390 - loss: 2.2418 - val_accuracy: 0.5928 - val_loss: 1.8987\n",
            "Epoch 3/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 13ms/step - accuracy: 0.6248 - loss: 1.6199 - val_accuracy: 0.6262 - val_loss: 1.7129\n",
            "Epoch 4/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 13ms/step - accuracy: 0.6825 - loss: 1.2380 - val_accuracy: 0.6418 - val_loss: 1.6441\n",
            "Epoch 5/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 13ms/step - accuracy: 0.7289 - loss: 0.9841 - val_accuracy: 0.6499 - val_loss: 1.6388\n",
            "Epoch 6/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 13ms/step - accuracy: 0.7637 - loss: 0.8193 - val_accuracy: 0.6525 - val_loss: 1.6703\n",
            "Epoch 7/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 13ms/step - accuracy: 0.7877 - loss: 0.7145 - val_accuracy: 0.6545 - val_loss: 1.6995\n",
            "Epoch 8/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 13ms/step - accuracy: 0.8049 - loss: 0.6440 - val_accuracy: 0.6561 - val_loss: 1.7255\n",
            "Epoch 9/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 13ms/step - accuracy: 0.8176 - loss: 0.5945 - val_accuracy: 0.6545 - val_loss: 1.7678\n",
            "Epoch 10/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 13ms/step - accuracy: 0.8272 - loss: 0.5573 - val_accuracy: 0.6580 - val_loss: 1.7941\n",
            "Epoch 11/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 13ms/step - accuracy: 0.8364 - loss: 0.5246 - val_accuracy: 0.6566 - val_loss: 1.8441\n",
            "Epoch 12/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 13ms/step - accuracy: 0.8431 - loss: 0.5004 - val_accuracy: 0.6568 - val_loss: 1.8590\n",
            "Epoch 13/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 13ms/step - accuracy: 0.8489 - loss: 0.4824 - val_accuracy: 0.6587 - val_loss: 1.8722\n",
            "Epoch 14/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 13ms/step - accuracy: 0.8526 - loss: 0.4658 - val_accuracy: 0.6576 - val_loss: 1.9015\n",
            "Epoch 15/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 13ms/step - accuracy: 0.8565 - loss: 0.4548 - val_accuracy: 0.6583 - val_loss: 1.9086\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7bef1435a9f0>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "seq2seq_rnn.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    weighted_metrics=[\"accuracy\"],\n",
        ")\n",
        "seq2seq_rnn.fit(train_ds, epochs=15, validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1CdxA7-yGfS",
        "outputId": "8d8858ae-a236-4ef5-f35f-186862789bdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "I went into the town in search of a good restaurant.\n",
            "[start] fui al pueblo en un restaurante cercano [end]\n",
            "-\n",
            "What an amusing situation!\n",
            "[start] ¡qué [UNK] más divertida [end]\n",
            "-\n",
            "Tom has something in his right hand.\n",
            "[start] tom tiene algo en la mano en su mano [end]\n",
            "-\n",
            "Who do you think I am?\n",
            "[start] quién crees que soy [end]\n",
            "-\n",
            "This apple is sour.\n",
            "[start] esta manzana es agria [end]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "spa_vocab = spanish_tokenizer.get_vocabulary()\n",
        "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
        "\n",
        "def generate_translation(input_sentence):\n",
        "    tokenized_input_sentence = english_tokenizer([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(sequence_length):\n",
        "        tokenized_target_sentence = spanish_tokenizer([decoded_sentence])\n",
        "        inputs = [tokenized_input_sentence, tokenized_target_sentence]\n",
        "        next_token_predictions = seq2seq_rnn.predict(inputs, verbose=0)\n",
        "        sampled_token_index = np.argmax(next_token_predictions[0, i, :])\n",
        "        sampled_token = spa_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "    return decoded_sentence\n",
        "\n",
        "test_eng_texts = [pair[0] for pair in test_pairs]\n",
        "for _ in range(5):\n",
        "    input_sentence = random.choice(test_eng_texts)\n",
        "    print(\"-\")\n",
        "    print(input_sentence)\n",
        "    print(generate_translation(input_sentence))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2AetkxoyGfT"
      },
      "source": [
        "### The Transformer architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-Mj96tKyGfT"
      },
      "source": [
        "#### Dot-product attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipaq_QdQyGfT"
      },
      "source": [
        "#### Transformer encoder block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "XEqAM_jNyGfT"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoder(keras.Layer):\n",
        "    def __init__(self, hidden_dim, intermediate_dim, num_heads):\n",
        "        super().__init__()\n",
        "        key_dim = hidden_dim // num_heads\n",
        "        self.self_attention = layers.MultiHeadAttention(num_heads, key_dim)\n",
        "        self.self_attention_layernorm = layers.LayerNormalization()\n",
        "        self.feed_forward_1 = layers.Dense(intermediate_dim, activation=\"relu\")\n",
        "        self.feed_forward_2 = layers.Dense(hidden_dim)\n",
        "        self.feed_forward_layernorm = layers.LayerNormalization()\n",
        "\n",
        "    def call(self, source, source_mask):\n",
        "        residual = x = source\n",
        "        mask = source_mask[:, None, :]\n",
        "        x = self.self_attention(query=x, key=x, value=x, attention_mask=mask)\n",
        "        x = x + residual\n",
        "        x = self.self_attention_layernorm(x)\n",
        "        residual = x\n",
        "        x = self.feed_forward_1(x)\n",
        "        x = self.feed_forward_2(x)\n",
        "        x = x + residual\n",
        "        x = self.feed_forward_layernorm(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qH3xAPfQyGfT"
      },
      "source": [
        "#### Transformer decoder block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "FKQR2UAzyGfT"
      },
      "outputs": [],
      "source": [
        "class TransformerDecoder(keras.Layer):\n",
        "    def __init__(self, hidden_dim, intermediate_dim, num_heads):\n",
        "        super().__init__()\n",
        "        key_dim = hidden_dim // num_heads\n",
        "        self.self_attention = layers.MultiHeadAttention(num_heads, key_dim)\n",
        "        self.self_attention_layernorm = layers.LayerNormalization()\n",
        "        self.cross_attention = layers.MultiHeadAttention(num_heads, key_dim)\n",
        "        self.cross_attention_layernorm = layers.LayerNormalization()\n",
        "        self.feed_forward_1 = layers.Dense(intermediate_dim, activation=\"relu\")\n",
        "        self.feed_forward_2 = layers.Dense(hidden_dim)\n",
        "        self.feed_forward_layernorm = layers.LayerNormalization()\n",
        "\n",
        "    def call(self, target, source, source_mask):\n",
        "        residual = x = target\n",
        "        x = self.self_attention(query=x, key=x, value=x, use_causal_mask=True)\n",
        "        x = x + residual\n",
        "        x = self.self_attention_layernorm(x)\n",
        "        residual = x\n",
        "        mask = source_mask[:, None, :]\n",
        "        x = self.cross_attention(\n",
        "            query=x, key=source, value=source, attention_mask=mask\n",
        "        )\n",
        "        x = x + residual\n",
        "        x = self.cross_attention_layernorm(x)\n",
        "        residual = x\n",
        "        x = self.feed_forward_1(x)\n",
        "        x = self.feed_forward_2(x)\n",
        "        x = x + residual\n",
        "        x = self.feed_forward_layernorm(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FBY76LcyGfT"
      },
      "source": [
        "#### Sequence-to-sequence learning with a Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "XnvYwICfyGfT"
      },
      "outputs": [],
      "source": [
        "hidden_dim = 256\n",
        "intermediate_dim = 2048\n",
        "num_heads = 8\n",
        "\n",
        "source = keras.Input(shape=(None,), dtype=\"int32\", name=\"english\")\n",
        "x = layers.Embedding(vocab_size, hidden_dim)(source)\n",
        "encoder_output = TransformerEncoder(hidden_dim, intermediate_dim, num_heads)(\n",
        "    source=x,\n",
        "    source_mask=source != 0,\n",
        ")\n",
        "\n",
        "target = keras.Input(shape=(None,), dtype=\"int32\", name=\"spanish\")\n",
        "x = layers.Embedding(vocab_size, hidden_dim)(target)\n",
        "x = TransformerDecoder(hidden_dim, intermediate_dim, num_heads)(\n",
        "    target=x,\n",
        "    source=encoder_output,\n",
        "    source_mask=source != 0,\n",
        ")\n",
        "x = layers.Dropout(0.5)(x)\n",
        "target_predictions = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "transformer = keras.Model([source, target], target_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "id": "HP2yNtZbyGfT",
        "outputId": "e7586734-a242-4ba9-fd67-a06c4ab15298"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m    Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to      \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ english (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │           \u001b[38;5;34m0\u001b[0m │ -                  │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ embedding_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │   \u001b[38;5;34m3,840,000\u001b[0m │ english[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)           │                   │             │                    │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ not_equal_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │           \u001b[38;5;34m0\u001b[0m │ english[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mNotEqual\u001b[0m)            │                   │             │                    │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ spanish (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │           \u001b[38;5;34m0\u001b[0m │ -                  │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ transformer_encoder   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │   \u001b[38;5;34m1,315,072\u001b[0m │ embedding_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)  │                   │             │ not_equal_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ not_equal_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │           \u001b[38;5;34m0\u001b[0m │ english[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mNotEqual\u001b[0m)            │                   │             │                    │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ embedding_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │   \u001b[38;5;34m3,840,000\u001b[0m │ spanish[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)           │                   │             │                    │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ transformer_decoder   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │   \u001b[38;5;34m1,578,752\u001b[0m │ transformer_encod… │\n",
              "│ (\u001b[38;5;33mTransformerDecoder\u001b[0m)  │                   │             │ not_equal_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│                       │                   │             │ embedding_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │           \u001b[38;5;34m0\u001b[0m │ transformer_decod… │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │   \u001b[38;5;34m3,855,000\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│                       │ \u001b[38;5;34m15000\u001b[0m)            │             │                    │\n",
              "└───────────────────────┴───────────────────┴─────────────┴────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)          </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">     Param # </span>┃<span style=\"font-weight: bold\"> Connected to       </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ english (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                  │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ embedding_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │   <span style=\"color: #00af00; text-decoration-color: #00af00\">3,840,000</span> │ english[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │                   │             │                    │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ not_equal_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ english[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)            │                   │             │                    │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ spanish (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                  │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ transformer_encoder   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │   <span style=\"color: #00af00; text-decoration-color: #00af00\">1,315,072</span> │ embedding_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)  │                   │             │ not_equal_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ not_equal_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ english[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)            │                   │             │                    │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ embedding_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │   <span style=\"color: #00af00; text-decoration-color: #00af00\">3,840,000</span> │ spanish[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │                   │             │                    │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ transformer_decoder   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │   <span style=\"color: #00af00; text-decoration-color: #00af00\">1,578,752</span> │ transformer_encod… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)  │                   │             │ not_equal_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│                       │                   │             │ embedding_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ transformer_decod… │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">3,855,000</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│                       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">15000</span>)            │             │                    │\n",
              "└───────────────────────┴───────────────────┴─────────────┴────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,428,824\u001b[0m (55.04 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,428,824</span> (55.04 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14,428,824\u001b[0m (55.04 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,428,824</span> (55.04 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "transformer.summary(line_length=80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VX3Hj0vpyGfT",
        "outputId": "d1ec484a-6e87-48de-d36d-45b4e08a8dd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 23ms/step - accuracy: 0.3644 - loss: 1.4806 - val_accuracy: 0.5008 - val_loss: 1.0258\n",
            "Epoch 2/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5361 - loss: 0.9608 - val_accuracy: 0.5765 - val_loss: 0.8226\n",
            "Epoch 3/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6060 - loss: 0.7544 - val_accuracy: 0.5996 - val_loss: 0.7565\n",
            "Epoch 4/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6507 - loss: 0.6276 - val_accuracy: 0.6147 - val_loss: 0.7306\n",
            "Epoch 5/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6833 - loss: 0.5423 - val_accuracy: 0.6237 - val_loss: 0.7260\n",
            "Epoch 6/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7091 - loss: 0.4790 - val_accuracy: 0.6262 - val_loss: 0.7304\n",
            "Epoch 7/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7311 - loss: 0.4300 - val_accuracy: 0.6322 - val_loss: 0.7234\n",
            "Epoch 8/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7495 - loss: 0.3901 - val_accuracy: 0.6350 - val_loss: 0.7408\n",
            "Epoch 9/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7658 - loss: 0.3573 - val_accuracy: 0.6373 - val_loss: 0.7497\n",
            "Epoch 10/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7805 - loss: 0.3300 - val_accuracy: 0.6378 - val_loss: 0.7564\n",
            "Epoch 11/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7920 - loss: 0.3076 - val_accuracy: 0.6383 - val_loss: 0.7775\n",
            "Epoch 12/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8030 - loss: 0.2882 - val_accuracy: 0.6374 - val_loss: 0.7991\n",
            "Epoch 13/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8126 - loss: 0.2707 - val_accuracy: 0.6378 - val_loss: 0.8187\n",
            "Epoch 14/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8212 - loss: 0.2562 - val_accuracy: 0.6375 - val_loss: 0.8401\n",
            "Epoch 15/15\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8287 - loss: 0.2426 - val_accuracy: 0.6386 - val_loss: 0.8436\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7bef0d06c290>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "transformer.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    weighted_metrics=[\"accuracy\"],\n",
        ")\n",
        "transformer.fit(train_ds, epochs=15, validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_53QRPeyGfT"
      },
      "source": [
        "#### Embedding positional information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "PPsqeKV8yGfT"
      },
      "outputs": [],
      "source": [
        "from keras import ops\n",
        "\n",
        "class PositionalEmbedding(keras.Layer):\n",
        "    def __init__(self, sequence_length, input_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.token_embeddings = layers.Embedding(input_dim, output_dim)\n",
        "        self.position_embeddings = layers.Embedding(sequence_length, output_dim)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        positions = ops.cumsum(ops.ones_like(inputs), axis=-1) - 1\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "r-S3c8V8yGfT"
      },
      "outputs": [],
      "source": [
        "hidden_dim = 256\n",
        "intermediate_dim = 2056\n",
        "num_heads = 8\n",
        "\n",
        "source = keras.Input(shape=(None,), dtype=\"int32\", name=\"english\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, hidden_dim)(source)\n",
        "encoder_output = TransformerEncoder(hidden_dim, intermediate_dim, num_heads)(\n",
        "    source=x,\n",
        "    source_mask=source != 0,\n",
        ")\n",
        "\n",
        "target = keras.Input(shape=(None,), dtype=\"int32\", name=\"spanish\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, hidden_dim)(target)\n",
        "x = TransformerDecoder(hidden_dim, intermediate_dim, num_heads)(\n",
        "    target=x,\n",
        "    source=encoder_output,\n",
        "    source_mask=source != 0,\n",
        ")\n",
        "x = layers.Dropout(0.5)(x)\n",
        "target_predictions = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "transformer = keras.Model([source, target], target_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ye3PIHCUyGfT",
        "outputId": "35ac5fda-723d-42e9-a931-37560754bf00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 21ms/step - accuracy: 0.3849 - loss: 1.4305 - val_accuracy: 0.5313 - val_loss: 0.9642\n",
            "Epoch 2/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5693 - loss: 0.8973 - val_accuracy: 0.6144 - val_loss: 0.7562\n",
            "Epoch 3/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6410 - loss: 0.6973 - val_accuracy: 0.6468 - val_loss: 0.6799\n",
            "Epoch 4/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6839 - loss: 0.5801 - val_accuracy: 0.6647 - val_loss: 0.6362\n",
            "Epoch 5/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7134 - loss: 0.5007 - val_accuracy: 0.6732 - val_loss: 0.6250\n",
            "Epoch 6/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7353 - loss: 0.4447 - val_accuracy: 0.6766 - val_loss: 0.6264\n",
            "Epoch 7/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7548 - loss: 0.3998 - val_accuracy: 0.6811 - val_loss: 0.6265\n",
            "Epoch 8/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7711 - loss: 0.3631 - val_accuracy: 0.6830 - val_loss: 0.6285\n",
            "Epoch 9/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7852 - loss: 0.3331 - val_accuracy: 0.6839 - val_loss: 0.6357\n",
            "Epoch 10/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7972 - loss: 0.3076 - val_accuracy: 0.6837 - val_loss: 0.6430\n",
            "Epoch 11/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8082 - loss: 0.2863 - val_accuracy: 0.6868 - val_loss: 0.6600\n",
            "Epoch 12/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8183 - loss: 0.2683 - val_accuracy: 0.6865 - val_loss: 0.6673\n",
            "Epoch 13/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8269 - loss: 0.2512 - val_accuracy: 0.6864 - val_loss: 0.6726\n",
            "Epoch 14/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8341 - loss: 0.2383 - val_accuracy: 0.6867 - val_loss: 0.6912\n",
            "Epoch 15/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8421 - loss: 0.2245 - val_accuracy: 0.6900 - val_loss: 0.6991\n",
            "Epoch 16/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8482 - loss: 0.2137 - val_accuracy: 0.6878 - val_loss: 0.7067\n",
            "Epoch 17/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8534 - loss: 0.2046 - val_accuracy: 0.6872 - val_loss: 0.7174\n",
            "Epoch 18/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8589 - loss: 0.1952 - val_accuracy: 0.6884 - val_loss: 0.7219\n",
            "Epoch 19/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8640 - loss: 0.1867 - val_accuracy: 0.6882 - val_loss: 0.7392\n",
            "Epoch 20/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8687 - loss: 0.1790 - val_accuracy: 0.6894 - val_loss: 0.7555\n",
            "Epoch 21/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8734 - loss: 0.1721 - val_accuracy: 0.6895 - val_loss: 0.7631\n",
            "Epoch 22/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8765 - loss: 0.1666 - val_accuracy: 0.6889 - val_loss: 0.7660\n",
            "Epoch 23/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8805 - loss: 0.1607 - val_accuracy: 0.6888 - val_loss: 0.7829\n",
            "Epoch 24/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8840 - loss: 0.1557 - val_accuracy: 0.6880 - val_loss: 0.7896\n",
            "Epoch 25/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8876 - loss: 0.1501 - val_accuracy: 0.6899 - val_loss: 0.7872\n",
            "Epoch 26/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8903 - loss: 0.1453 - val_accuracy: 0.6894 - val_loss: 0.7943\n",
            "Epoch 27/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8930 - loss: 0.1420 - val_accuracy: 0.6875 - val_loss: 0.7875\n",
            "Epoch 28/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8957 - loss: 0.1369 - val_accuracy: 0.6877 - val_loss: 0.7952\n",
            "Epoch 29/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8987 - loss: 0.1332 - val_accuracy: 0.6887 - val_loss: 0.7970\n",
            "Epoch 30/30\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9008 - loss: 0.1301 - val_accuracy: 0.6880 - val_loss: 0.7941\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7bef0c198620>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "transformer.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    weighted_metrics=[\"accuracy\"],\n",
        ")\n",
        "transformer.fit(train_ds, epochs=30, validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgNlT_vhyGfT",
        "outputId": "647fceb7-69cd-4433-a402-941b32eceb74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "She doesn't believe in God.\n",
            "[start] ella no cree en dios [end]\n",
            "-\n",
            "The vampire movie filled them with terror.\n",
            "[start] los [UNK] la película los [UNK] [end]\n",
            "-\n",
            "Let me have a try at it.\n",
            "[start] déjame probarlo [end]\n",
            "-\n",
            "They grind wheat into flour.\n",
            "[start] [UNK] atentamente las harina en harina [end]\n",
            "-\n",
            "Hurry up or we'll miss the train!\n",
            "[start] apresúrate o perderás el tren [end]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "spa_vocab = spanish_tokenizer.get_vocabulary()\n",
        "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
        "\n",
        "def generate_translation(input_sentence):\n",
        "    tokenized_input_sentence = english_tokenizer([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(sequence_length):\n",
        "        tokenized_target_sentence = spanish_tokenizer([decoded_sentence])\n",
        "        tokenized_target_sentence = tokenized_target_sentence[:, :-1]\n",
        "        inputs = [tokenized_input_sentence, tokenized_target_sentence]\n",
        "        next_token_predictions = transformer.predict(inputs, verbose=0)\n",
        "        sampled_token_index = np.argmax(next_token_predictions[0, i, :])\n",
        "        sampled_token = spa_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "    return decoded_sentence\n",
        "\n",
        "test_eng_texts = [pair[0] for pair in test_pairs]\n",
        "for _ in range(5):\n",
        "    input_sentence = random.choice(test_eng_texts)\n",
        "    print(\"-\")\n",
        "    print(input_sentence)\n",
        "    print(generate_translation(input_sentence))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oCEKPEwyGfT"
      },
      "source": [
        "### Classification with a pretrained Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGlVMglFyGfT"
      },
      "source": [
        "#### Pretraining a Transformer encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sm8dowaayGfU"
      },
      "source": [
        "#### Loading a pretrained Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JESDuAMyGfU",
        "outputId": "3034363a-82e5-439a-fbb5-868167eaf095"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/roberta/keras/roberta_base_en/3/download/config.json...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 445/445 [00:00<00:00, 745kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/roberta/keras/roberta_base_en/3/download/tokenizer.json...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 686/686 [00:00<00:00, 1.32MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/roberta/keras/roberta_base_en/3/download/assets/tokenizer/vocabulary.json...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 0.99M/0.99M [00:01<00:00, 732kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/roberta/keras/roberta_base_en/3/download/assets/tokenizer/merges.txt...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 446k/446k [00:01<00:00, 419kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/roberta/keras/roberta_base_en/3/download/model.weights.h5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 474M/474M [00:30<00:00, 16.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "import keras_hub\n",
        "\n",
        "tokenizer = keras_hub.models.Tokenizer.from_preset(\"roberta_base_en\")\n",
        "backbone = keras_hub.models.Backbone.from_preset(\"roberta_base_en\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jv444aeJyGfU",
        "outputId": "90b0a3a5-59a2-4c7e-ce5e-d3ae0e886ea4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([  133,  2119,  6219, 23602], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "tokenizer(\"The quick brown fox\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 945
        },
        "id": "m9Q-K5d-yGfU",
        "outputId": "c375bd1e-0518-48d1-cbaa-7effc63b5562"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"roberta_backbone\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"roberta_backbone\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m    Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to      \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ token_ids             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │           \u001b[38;5;34m0\u001b[0m │ -                  │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)          │                   │             │                    │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ embeddings            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m38,996,736\u001b[0m │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mTokenAndPositionEmb…\u001b[0m │                   │             │                    │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ embeddings_layer_norm │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │       \u001b[38;5;34m1,536\u001b[0m │ embeddings[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)  │                   │             │                    │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ embeddings_dropout    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │           \u001b[38;5;34m0\u001b[0m │ embeddings_layer_… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)             │                   │             │                    │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ padding_mask          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │           \u001b[38;5;34m0\u001b[0m │ -                  │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)          │                   │             │                    │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ transformer_layer_0   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │   \u001b[38;5;34m7,087,872\u001b[0m │ embeddings_dropou… │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)  │                   │             │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ transformer_layer_1   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │   \u001b[38;5;34m7,087,872\u001b[0m │ transformer_layer… │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)  │                   │             │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ transformer_layer_2   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │   \u001b[38;5;34m7,087,872\u001b[0m │ transformer_layer… │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)  │                   │             │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ transformer_layer_3   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │   \u001b[38;5;34m7,087,872\u001b[0m │ transformer_layer… │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)  │                   │             │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ transformer_layer_4   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │   \u001b[38;5;34m7,087,872\u001b[0m │ transformer_layer… │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)  │                   │             │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ transformer_layer_5   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │   \u001b[38;5;34m7,087,872\u001b[0m │ transformer_layer… │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)  │                   │             │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ transformer_layer_6   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │   \u001b[38;5;34m7,087,872\u001b[0m │ transformer_layer… │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)  │                   │             │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ transformer_layer_7   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │   \u001b[38;5;34m7,087,872\u001b[0m │ transformer_layer… │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)  │                   │             │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ transformer_layer_8   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │   \u001b[38;5;34m7,087,872\u001b[0m │ transformer_layer… │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)  │                   │             │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ transformer_layer_9   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │   \u001b[38;5;34m7,087,872\u001b[0m │ transformer_layer… │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)  │                   │             │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ transformer_layer_10  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │   \u001b[38;5;34m7,087,872\u001b[0m │ transformer_layer… │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)  │                   │             │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ transformer_layer_11  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │   \u001b[38;5;34m7,087,872\u001b[0m │ transformer_layer… │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)  │                   │             │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "└───────────────────────┴───────────────────┴─────────────┴────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)          </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">     Param # </span>┃<span style=\"font-weight: bold\"> Connected to       </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ token_ids             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │                   │             │                    │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ embeddings            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">38,996,736</span> │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionEmb…</span> │                   │             │                    │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ embeddings_layer_norm │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │ embeddings[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)  │                   │             │                    │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ embeddings_dropout    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embeddings_layer_… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │                   │             │                    │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ padding_mask          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │                   │             │                    │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ transformer_layer_0   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │   <span style=\"color: #00af00; text-decoration-color: #00af00\">7,087,872</span> │ embeddings_dropou… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)  │                   │             │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ transformer_layer_1   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │   <span style=\"color: #00af00; text-decoration-color: #00af00\">7,087,872</span> │ transformer_layer… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)  │                   │             │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ transformer_layer_2   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │   <span style=\"color: #00af00; text-decoration-color: #00af00\">7,087,872</span> │ transformer_layer… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)  │                   │             │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ transformer_layer_3   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │   <span style=\"color: #00af00; text-decoration-color: #00af00\">7,087,872</span> │ transformer_layer… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)  │                   │             │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ transformer_layer_4   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │   <span style=\"color: #00af00; text-decoration-color: #00af00\">7,087,872</span> │ transformer_layer… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)  │                   │             │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ transformer_layer_5   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │   <span style=\"color: #00af00; text-decoration-color: #00af00\">7,087,872</span> │ transformer_layer… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)  │                   │             │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ transformer_layer_6   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │   <span style=\"color: #00af00; text-decoration-color: #00af00\">7,087,872</span> │ transformer_layer… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)  │                   │             │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ transformer_layer_7   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │   <span style=\"color: #00af00; text-decoration-color: #00af00\">7,087,872</span> │ transformer_layer… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)  │                   │             │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ transformer_layer_8   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │   <span style=\"color: #00af00; text-decoration-color: #00af00\">7,087,872</span> │ transformer_layer… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)  │                   │             │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ transformer_layer_9   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │   <span style=\"color: #00af00; text-decoration-color: #00af00\">7,087,872</span> │ transformer_layer… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)  │                   │             │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ transformer_layer_10  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │   <span style=\"color: #00af00; text-decoration-color: #00af00\">7,087,872</span> │ transformer_layer… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)  │                   │             │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├───────────────────────┼───────────────────┼─────────────┼────────────────────┤\n",
              "│ transformer_layer_11  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │   <span style=\"color: #00af00; text-decoration-color: #00af00\">7,087,872</span> │ transformer_layer… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)  │                   │             │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "└───────────────────────┴───────────────────┴─────────────┴────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m124,052,736\u001b[0m (473.22 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">124,052,736</span> (473.22 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m124,052,736\u001b[0m (473.22 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">124,052,736</span> (473.22 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "backbone.summary(line_length=80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4kseP8ZyGfU"
      },
      "source": [
        "#### Preprocessing IMDb movie reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFgbhdREyGfU",
        "outputId": "692b6236-9bcb-44de-bf09-eef23af499c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "\u001b[1m84125825/84125825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "import os, pathlib, shutil, random\n",
        "\n",
        "zip_path = keras.utils.get_file(\n",
        "    origin=\"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\",\n",
        "    fname=\"imdb\",\n",
        "    extract=True,\n",
        ")\n",
        "\n",
        "imdb_extract_dir = pathlib.Path(zip_path) / \"aclImdb\"\n",
        "train_dir = pathlib.Path(\"imdb_train\")\n",
        "test_dir = pathlib.Path(\"imdb_test\")\n",
        "val_dir = pathlib.Path(\"imdb_val\")\n",
        "\n",
        "shutil.copytree(imdb_extract_dir / \"test\", test_dir, dirs_exist_ok=True)\n",
        "\n",
        "val_percentage = 0.2\n",
        "for category in (\"neg\", \"pos\"):\n",
        "    src_dir = imdb_extract_dir / \"train\" / category\n",
        "    src_files = os.listdir(src_dir)\n",
        "    random.Random(1337).shuffle(src_files)\n",
        "    num_val_samples = int(len(src_files) * val_percentage)\n",
        "\n",
        "    os.makedirs(train_dir / category, exist_ok=True)\n",
        "    os.makedirs(val_dir / category, exist_ok=True)\n",
        "    for index, file in enumerate(src_files):\n",
        "        if index < num_val_samples:\n",
        "            shutil.copy(src_dir / file, val_dir / category / file)\n",
        "        else:\n",
        "            shutil.copy(src_dir / file, train_dir / category / file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1w1wEu7yGfU",
        "outputId": "4fff6b50-f953-4e0b-837b-75e35f4d84f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Found 5000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from keras.utils import text_dataset_from_directory\n",
        "\n",
        "batch_size = 16\n",
        "train_ds = text_dataset_from_directory(train_dir, batch_size=batch_size)\n",
        "val_ds = text_dataset_from_directory(val_dir, batch_size=batch_size)\n",
        "test_ds = text_dataset_from_directory(test_dir, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "hx-Y7ZfAyGfU"
      },
      "outputs": [],
      "source": [
        "def preprocess(text, label):\n",
        "    packer = keras_hub.layers.StartEndPacker(\n",
        "        sequence_length=512,\n",
        "        start_value=tokenizer.start_token_id,\n",
        "        end_value=tokenizer.end_token_id,\n",
        "        pad_value=tokenizer.pad_token_id,\n",
        "        return_padding_mask=True,\n",
        "    )\n",
        "    token_ids, padding_mask = packer(tokenizer(text))\n",
        "    return {\"token_ids\": token_ids, \"padding_mask\": padding_mask}, label\n",
        "\n",
        "preprocessed_train_ds = train_ds.map(preprocess)\n",
        "preprocessed_val_ds = val_ds.map(preprocess)\n",
        "preprocessed_test_ds = test_ds.map(preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JynsJUdyGfU",
        "outputId": "482e90bb-d9e6-4266-d02a-37d713702b0c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'token_ids': <tf.Tensor: shape=(16, 512), dtype=int32, numpy=\n",
              "  array([[    0,  7199,    10, ...,     1,     1,     1],\n",
              "         [    0, 15622,  6821, ...,     1,     1,     1],\n",
              "         [    0,   100,   348, ...,     1,     1,     1],\n",
              "         ...,\n",
              "         [    0,  8346,   147, ...,     1,     1,     1],\n",
              "         [    0,  1620,  3997, ...,     1,     1,     1],\n",
              "         [    0,  1640,  4182, ...,     1,     1,     1]], dtype=int32)>,\n",
              "  'padding_mask': <tf.Tensor: shape=(16, 512), dtype=bool, numpy=\n",
              "  array([[ True,  True,  True, ..., False, False, False],\n",
              "         [ True,  True,  True, ..., False, False, False],\n",
              "         [ True,  True,  True, ..., False, False, False],\n",
              "         ...,\n",
              "         [ True,  True,  True, ..., False, False, False],\n",
              "         [ True,  True,  True, ..., False, False, False],\n",
              "         [ True,  True,  True, ..., False, False, False]])>},\n",
              " <tf.Tensor: shape=(16,), dtype=int32, numpy=array([1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "next(iter(preprocessed_train_ds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBkvzLBjyGfU"
      },
      "source": [
        "#### Fine-tuning a pretrained Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "S_4Bz2BfyGfU"
      },
      "outputs": [],
      "source": [
        "inputs = backbone.input\n",
        "x = backbone(inputs)\n",
        "x = x[:, 0, :]\n",
        "x = layers.Dropout(0.1)(x)\n",
        "x = layers.Dense(768, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "classifier = keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5xJowrSyGfU",
        "outputId": "b5f4b6f1-a2cd-4ec9-ed59-d3326f75c70c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 119ms/step - accuracy: 0.9038 - loss: 0.2522 - val_accuracy: 0.9266 - val_loss: 0.1981\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7beecfbad250>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "classifier.compile(\n",
        "    optimizer=keras.optimizers.Adam(5e-5),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "classifier.fit(\n",
        "    preprocessed_train_ds,\n",
        "    validation_data=preprocessed_val_ds,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVn4zqQ_yGfU",
        "outputId": "ad02bf40-9912-407f-e1a6-28cb7c49c737"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 35ms/step - accuracy: 0.9343 - loss: 0.1858\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.18578200042247772, 0.9343199729919434]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "classifier.evaluate(preprocessed_test_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MzSJw34yGfU"
      },
      "source": [
        "### What makes the Transformer effective?"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "chapter15_language-models-and-the-transformer",
      "provenance": [],
      "toc_visible": true,
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}